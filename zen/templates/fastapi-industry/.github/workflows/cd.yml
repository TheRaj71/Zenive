name: CD Pipeline

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        default: false
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHON_VERSION: "3.11"

jobs:
  # Determine deployment environment and strategy
  setup:
    name: Setup Deployment
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      image_tag: ${{ steps.tag.outputs.tag }}
      deploy_to_staging: ${{ steps.env.outputs.deploy_to_staging }}
      deploy_to_production: ${{ steps.env.outputs.deploy_to_production }}
    
    steps:
    - name: Determine environment
      id: env
      run: |
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          echo "deploy_to_staging=${{ github.event.inputs.environment == 'staging' }}" >> $GITHUB_OUTPUT
          echo "deploy_to_production=${{ github.event.inputs.environment == 'production' }}" >> $GITHUB_OUTPUT
        elif [[ "${{ github.ref }}" == refs/tags/v* ]]; then
          echo "environment=production" >> $GITHUB_OUTPUT
          echo "deploy_to_staging=false" >> $GITHUB_OUTPUT
          echo "deploy_to_production=true" >> $GITHUB_OUTPUT
        else
          echo "environment=staging" >> $GITHUB_OUTPUT
          echo "deploy_to_staging=true" >> $GITHUB_OUTPUT
          echo "deploy_to_production=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Generate image tag
      id: tag
      run: |
        if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
          echo "tag=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
        else
          echo "tag=${{ github.sha }}" >> $GITHUB_OUTPUT
        fi

  # Build and push Docker images
  build-and-push:
    name: Build & Push Images
    runs-on: ubuntu-latest
    needs: setup
    permissions:
      contents: read
      packages: write
    
    strategy:
      matrix:
        image: [api, worker, nginx]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.image }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./deployment/docker/Dockerfile.${{ matrix.image }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

  # Deploy to staging environment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [setup, build-and-push]
    if: needs.setup.outputs.deploy_to_staging == 'true'
    environment:
      name: staging
      url: https://api-staging.{{project_name}}.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name {{project_name}}-staging
    
    - name: Deploy to Kubernetes
      run: |
        # Update image tags in deployment manifests
        sed -i "s|{{project_name}}/api:latest|${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/api:${{ needs.setup.outputs.image_tag }}|g" deployment/k8s/deployment.yaml
        sed -i "s|{{project_name}}/worker:latest|${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/worker:${{ needs.setup.outputs.image_tag }}|g" deployment/k8s/deployment.yaml
        
        # Apply Kubernetes manifests
        kubectl apply -f deployment/k8s/namespace.yaml
        kubectl apply -f deployment/k8s/configmap.yaml
        kubectl apply -f deployment/k8s/secrets.yaml
        kubectl apply -f deployment/k8s/rbac.yaml
        kubectl apply -f deployment/k8s/deployment.yaml
        kubectl apply -f deployment/k8s/service.yaml
        kubectl apply -f deployment/k8s/ingress.yaml
        kubectl apply -f deployment/k8s/hpa.yaml
        
        # Wait for deployment to complete
        kubectl rollout status deployment/{{project_name}}-api -n {{project_name}} --timeout=600s
        kubectl rollout status deployment/{{project_name}}-worker -n {{project_name}} --timeout=600s
    
    - name: Run database migrations
      run: |
        kubectl exec -n {{project_name}} deployment/{{project_name}}-api -- alembic upgrade head
    
    - name: Run smoke tests
      run: |
        # Wait for service to be ready
        sleep 30
        
        # Basic health check
        kubectl exec -n {{project_name}} deployment/{{project_name}}-api -- curl -f http://localhost:8000/health
        
        # Run smoke tests
        python -m pytest tests/smoke/ --base-url=https://api-staging.{{project_name}}.com -v
    
    - name: Notify deployment success
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#deployments'
        text: 'üöÄ Successfully deployed to staging: https://api-staging.{{project_name}}.com'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Run end-to-end tests on staging
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: needs.deploy-staging.result == 'success'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run E2E tests
      run: |
        pytest tests/e2e/ --base-url=https://api-staging.{{project_name}}.com -v --tb=short
      env:
        E2E_TEST_USER: ${{ secrets.E2E_TEST_USER }}
        E2E_TEST_PASSWORD: ${{ secrets.E2E_TEST_PASSWORD }}
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: |
          e2e-test-report.html
          screenshots/

  # Security and compliance checks
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: needs.deploy-staging.result == 'success'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run OWASP ZAP scan
      uses: zaproxy/action-full-scan@v0.7.0
      with:
        target: 'https://api-staging.{{project_name}}.com'
        rules_file_name: '.zap/rules.tsv'
        cmd_options: '-a'
        allow_issue_writing: false
    
    - name: Upload ZAP scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: zap-scan-results
        path: report_html.html

  # Deploy to production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [setup, build-and-push, e2e-tests, security-scan]
    if: |
      needs.setup.outputs.deploy_to_production == 'true' && 
      (needs.e2e-tests.result == 'success' || github.event.inputs.force_deploy == 'true')
    environment:
      name: production
      url: https://api.{{project_name}}.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name {{project_name}}-production
    
    - name: Create deployment backup
      run: |
        kubectl get deployment {{project_name}}-api -n {{project_name}} -o yaml > deployment-backup.yaml
        kubectl get deployment {{project_name}}-worker -n {{project_name}} -o yaml > worker-backup.yaml
    
    - name: Deploy to Production Kubernetes
      run: |
        # Update image tags in deployment manifests
        sed -i "s|{{project_name}}/api:latest|${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/api:${{ needs.setup.outputs.image_tag }}|g" deployment/k8s/deployment.yaml
        sed -i "s|{{project_name}}/worker:latest|${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/worker:${{ needs.setup.outputs.image_tag }}|g" deployment/k8s/deployment.yaml
        
        # Apply Kubernetes manifests with rolling update
        kubectl apply -f deployment/k8s/deployment.yaml
        
        # Wait for deployment to complete
        kubectl rollout status deployment/{{project_name}}-api -n {{project_name}} --timeout=900s
        kubectl rollout status deployment/{{project_name}}-worker -n {{project_name}} --timeout=900s
    
    - name: Run database migrations
      run: |
        kubectl exec -n {{project_name}} deployment/{{project_name}}-api -- alembic upgrade head
    
    - name: Verify production deployment
      run: |
        # Wait for service to be ready
        sleep 60
        
        # Health check
        kubectl exec -n {{project_name}} deployment/{{project_name}}-api -- curl -f http://localhost:8000/health
        
        # External health check
        curl -f https://api.{{project_name}}.com/health
    
    - name: Run production smoke tests
      run: |
        python -m pytest tests/smoke/ --base-url=https://api.{{project_name}}.com -v
    
    - name: Rollback on failure
      if: failure()
      run: |
        echo "Deployment failed, rolling back..."
        kubectl apply -f deployment-backup.yaml
        kubectl apply -f worker-backup.yaml
        kubectl rollout status deployment/{{project_name}}-api -n {{project_name}} --timeout=600s
        kubectl rollout status deployment/{{project_name}}-worker -n {{project_name}} --timeout=600s
    
    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: |
          ${{ job.status == 'success' && 'üéâ Successfully deployed to production!' || '‚ùå Production deployment failed!' }}
          Version: ${{ needs.setup.outputs.image_tag }}
          URL: https://api.{{project_name}}.com
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Post-deployment monitoring
  post-deploy-monitoring:
    name: Post-Deployment Monitoring
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: needs.deploy-production.result == 'success'
    
    steps:
    - name: Monitor application metrics
      run: |
        # Wait for metrics to stabilize
        sleep 300
        
        # Check error rate (should be < 1%)
        ERROR_RATE=$(curl -s "https://api.{{project_name}}.com/metrics" | grep "http_requests_total" | grep "5.." | awk '{sum+=$2} END {print sum/NR}')
        if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
          echo "High error rate detected: $ERROR_RATE"
          exit 1
        fi
        
        # Check response time (should be < 500ms)
        RESPONSE_TIME=$(curl -s "https://api.{{project_name}}.com/metrics" | grep "http_request_duration_seconds" | grep "quantile=\"0.95\"" | awk '{print $2}')
        if (( $(echo "$RESPONSE_TIME > 0.5" | bc -l) )); then
          echo "High response time detected: $RESPONSE_TIME"
          exit 1
        fi
    
    - name: Create GitHub release
      if: startsWith(github.ref, 'refs/tags/v')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        body: |
          ## Changes in this Release
          - Automated release from CD pipeline
          - Deployed to production: https://api.{{project_name}}.com
          
          ## Deployment Information
          - Image Tag: ${{ needs.setup.outputs.image_tag }}
          - Deployment Time: ${{ github.event.head_commit.timestamp }}
          - Commit: ${{ github.sha }}
        draft: false
        prerelease: false

  # Cleanup old deployments and images
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [deploy-production, post-deploy-monitoring]
    if: always()
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Cleanup old container images
      run: |
        # Keep only the last 10 images
        aws ecr list-images --repository-name {{project_name}}/api --filter tagStatus=UNTAGGED \
          --query 'imageIds[?imageDigest!=null]|sort_by(@, &imagePushedAt)|[0:-10]' \
          --output json | jq '.[] | select(.imageDigest != null) | .imageDigest' | \
          xargs -I {} aws ecr batch-delete-image --repository-name {{project_name}}/api --image-ids imageDigest={}
    
    - name: Cleanup old Kubernetes resources
      run: |
        # Update kubeconfig
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name {{project_name}}-staging
        
        # Clean up old replica sets (keep last 3)
        kubectl get rs -n {{project_name}} --sort-by=.metadata.creationTimestamp -o name | head -n -3 | xargs -r kubectl delete -n {{project_name}}